# LLM Configuration
# Copy this file to .env and fill in your actual values

# Primary LLM Provider (openai, anthropic, or local)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic/Claude Configuration (for enhanced proposal generation)
# Claude 4.5 with extended thinking mode produces comprehensive, winning proposals
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Proposal Generation Mode
# Options: template, claude_standard, claude_enhanced, claude_premium
# - template: Fast template-based generation (no API calls)
# - claude_standard: Claude Sonnet 4.5 without thinking
# - claude_enhanced: Claude Sonnet 4.5 with thinking (recommended)
# - claude_premium: Claude Opus 4.5 with thinking (highest quality, most expensive)
PROPOSAL_GENERATION_MODE=claude_enhanced

# Claude Thinking Mode Settings
# Enable extended thinking for more comprehensive proposals
CLAUDE_ENABLE_THINKING=true
# Token budget for Claude's thinking process (higher = more thorough analysis)
CLAUDE_THINKING_BUDGET=10000

# Model Selection
LLM_MODEL_NAME=gpt-5.1
# Alternative models: gpt-4o, gpt-4-turbo, gpt-3.5-turbo

# Generation Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=30
LLM_MAX_RETRIES=3

# Task-specific temperatures
BID_GENERATION_TEMP=0.7  # Higher for creative bid writing
EXTRACTION_TEMP=0.3      # Lower for precise requirement extraction
PRICING_TEMP=0.5         # Medium for pricing calculations

# Local Model Configuration (for future use)
LOCAL_MODEL_PATH=/path/to/local/model
LOCAL_MODEL_NAME=mistral-7b