# Example environment configuration for LLM infrastructure
# OpenAI Configuration (Primary option)
OPENAI_API_KEY=your_openai_api_key_here
# HuggingFace Configuration (Fallback option)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co/models
# LLM Provider Selection (optional - auto-detected if not set)
# Options: openai, huggingface, local
LLM_PROVIDER=openai
# Model Configuration Overrides (optional)
LLM_MODEL_NAME=gpt-4-turbo-preview
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=30.0